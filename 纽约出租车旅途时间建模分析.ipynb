{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据纽约出租车的运营数据，针对客户旅途时间展开分析与建模。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "from matplotlib import cm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from dateutil import parser\n",
    "import io\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "太远地方的就先去掉啦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "xlim = [-74.03, -73.77]\n",
    "ylim = [40.63, 40.85]\n",
    "df = df[(df.pickup_longitude> xlim[0]) & (df.pickup_longitude < xlim[1])]\n",
    "df = df[(df.dropoff_longitude> xlim[0]) & (df.dropoff_longitude < xlim[1])]\n",
    "df = df[(df.pickup_latitude> ylim[0]) & (df.pickup_latitude < ylim[1])]\n",
    "df = df[(df.dropoff_latitude> ylim[0]) & (df.dropoff_latitude < ylim[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上下车地点集中区域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "longitude = list(df.pickup_longitude) + list(df.dropoff_longitude)\n",
    "latitude = list(df.pickup_latitude) + list(df.dropoff_latitude)\n",
    "plt.figure(figsize = (10,10))\n",
    "plt.plot(longitude,latitude,'.', alpha = 0.4, markersize = 0.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "根据上下车的地点，将区域分一下，用聚类来试试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "loc_df = pd.DataFrame()\n",
    "loc_df['longitude'] = longitude\n",
    "loc_df['latitude'] = latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=15, random_state=2, n_init = 10).fit(loc_df)\n",
    "loc_df['label'] = kmeans.labels_\n",
    "\n",
    "loc_df = loc_df.sample(200000)\n",
    "plt.figure(figsize = (10,10))\n",
    "for label in loc_df.label.unique():\n",
    "    plt.plot(loc_df.longitude[loc_df.label == label],loc_df.latitude[loc_df.label == label],'.', alpha = 0.3, markersize = 0.3)\n",
    "\n",
    "plt.title('Clusters of New York')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "给区域来个标记吧"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (10,10))\n",
    "for label in loc_df.label.unique():\n",
    "    ax.plot(loc_df.longitude[loc_df.label == label],loc_df.latitude[loc_df.label == label],'.', alpha = 0.4, markersize = 0.1, color = 'gray')\n",
    "    ax.plot(kmeans.cluster_centers_[label,0],kmeans.cluster_centers_[label,1],'o', color = 'r')\n",
    "    ax.annotate(label, (kmeans.cluster_centers_[label,0],kmeans.cluster_centers_[label,1]), color = 'b', fontsize = 20)\n",
    "ax.set_title('Cluster Centers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['pickup_cluster'] = kmeans.predict(df[['pickup_longitude','pickup_latitude']])\n",
    "df['dropoff_cluster'] = kmeans.predict(df[['dropoff_longitude','dropoff_latitude']])\n",
    "df['pickup_hour'] = df.pickup_datetime.apply(lambda x: parser.parse(x).hour )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clusters = pd.DataFrame()\n",
    "clusters['x'] = kmeans.cluster_centers_[:,0]\n",
    "clusters['y'] = kmeans.cluster_centers_[:,1]\n",
    "clusters['label'] = range(len(clusters))\n",
    "\n",
    "loc_df = loc_df.sample(5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "展示了方向与趋势，箭头的宽度与车流成正比"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10,10))\n",
    "\n",
    "def animate(hour):\n",
    "    ax.clear()\n",
    "    ax.set_title('Relative Traffic - Hour ' + str(int(hour)) + ':00')    \n",
    "    plt.figure(figsize = (10,10))\n",
    "    for label in loc_df.label.unique():\n",
    "        ax.plot(loc_df.longitude[loc_df.label == label],loc_df.latitude[loc_df.label == label],'.', alpha = 1, markersize = 2, color = 'gray')\n",
    "        ax.plot(kmeans.cluster_centers_[label,0],kmeans.cluster_centers_[label,1],'o', color = 'r')\n",
    "\n",
    "\n",
    "    for label in clusters.label:\n",
    "        for dest_label in clusters.label:\n",
    "            num_of_rides = len(df[(df.pickup_cluster == label) & (df.dropoff_cluster == dest_label) & (df.pickup_hour == hour)])\n",
    "            dist_x = clusters.x[clusters.label == label].values[0] - clusters.x[clusters.label == dest_label].values[0]\n",
    "            dist_y = clusters.y[clusters.label == label].values[0] - clusters.y[clusters.label == dest_label].values[0]\n",
    "            pct = np.true_divide(num_of_rides,len(df[df.pickup_hour == hour]))\n",
    "            arr = Arrow(clusters.x[clusters.label == label].values, clusters.y[clusters.label == label].values, -dist_x, -dist_y, edgecolor='white', width = pct)\n",
    "            ax.add_patch(arr)\n",
    "            arr.set_facecolor('g')\n",
    "    return [Artist()]\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig,animate,sorted(df.pickup_hour.unique()), interval = 1000)\n",
    "plt.close()\n",
    "ani.save('html/animation2.html', writer='imagemagick', fps=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "邻居分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "neighborhood = {-74.0019368351: 'Chelsea',-73.837549761: 'Queens',-73.7854240738: 'JFK',-73.9810421975:'Midtown-North-West',-73.9862336241: 'East Village',\n",
    "                -73.971273324:'Midtown-North-East',-73.9866739677: 'Brooklyn-parkslope',-73.8690098118: 'LaGuardia',-73.9890572967:'Midtown',-74.0081765545: 'Downtown'\n",
    "                ,-73.9213024854: 'Queens-Astoria',-73.9470256923: 'Harlem',-73.9555565018: 'Uppe East Side',\n",
    "               -73.9453487097: 'Brooklyn-Williamsburgt',-73.9745967889:'Upper West Side'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rides_df = pd.DataFrame(columns = neighborhood.values())\n",
    "rides_df['name'] = neighborhood.values()\n",
    "\n",
    "neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "neigh.fit(np.array(list(neighborhood.keys())).reshape(-1, 1), list(neighborhood.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "df['pickup_neighborhood'] = neigh.predict(df.pickup_longitude.values.reshape(-1,1))\n",
    "df['dropoff_neighborhood'] = neigh.predict(df.dropoff_longitude.values.reshape(-1,1))\n",
    "\n",
    "for col in rides_df.columns[:-1]:\n",
    "    rides_df[col] = rides_df.name.apply(lambda x: len(df[(df.pickup_neighborhood == x) & (df.dropoff_neighborhood == col)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "rides_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "\n",
    "trace = go.Heatmap(z= np.array(rides_df.as_matrix()),\n",
    "                  x = rides_df.columns[:-1],\n",
    "                  y = rides_df.columns)\n",
    "layout = dict(\n",
    "    title = ' <b>Neighborhoods Interaction</b>',\n",
    "    titlefont = dict(\n",
    "    size = 30,\n",
    "    color = ('rgb(100,100,100)')),\n",
    "    margin = dict(t=100,r=100,b=100,l=150),\n",
    "        yaxis = dict(\n",
    "            title = ' <b> From </b>'),\n",
    "        xaxis = dict(\n",
    "            title = '<b> To </b>'))\n",
    "data=[trace]\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename='labelled-heatmap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "进出分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize = (12,12))\n",
    "for i in range(len(rides_df)):  \n",
    "    ax.plot(rides_df.sum(axis = 1)[i],rides_df.sum(axis = 0)[i],'o', color = 'b')\n",
    "    ax.annotate(rides_df.index.tolist()[i], (rides_df.sum(axis = 1)[i],rides_df.sum(axis = 0)[i]), color = 'b', fontsize = 12)\n",
    "\n",
    "ax.plot([0,250000],[0,250000], color = 'r', linewidth = 1)\n",
    "ax.grid('off')\n",
    "ax.set_xlim([0,250000])\n",
    "ax.set_ylim([0,250000])\n",
    "ax.set_xlabel('Outbound Taxis')\n",
    "ax.set_ylabel('Inbound Taxis')\n",
    "ax.set_title('Inbound and Outbound rides for each cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们可以看到，每个地区的出入的比率是相对平衡的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd  #pandas for using dataframe and reading csv \n",
    "import numpy as np   #numpy for vector operations and basic maths \n",
    "#import simplejson    #getting JSON in simplified format\n",
    "import urllib        #for url stuff\n",
    "#import gmaps       #for using google maps to visulalize places on maps\n",
    "import re            #for processing regular expressions\n",
    "import datetime      #for datetime operations\n",
    "import calendar      #for calendar for datetime operations\n",
    "import time          #to get the system time\n",
    "import scipy         #for other dependancies\n",
    "from sklearn.cluster import KMeans # for doing K-means clustering\n",
    "from haversine import haversine # for calculating haversine distance\n",
    "import math          #for basic maths operations\n",
    "import seaborn as sns #for making plots\n",
    "import matplotlib.pyplot as plt # for plotting\n",
    "import os  # for os commands\n",
    "from scipy.misc import imread, imresize, imsave  # for plots \n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from IPython.display import HTML\n",
    "from matplotlib.pyplot import *\n",
    "from matplotlib import cm\n",
    "from matplotlib import animation\n",
    "import io\n",
    "import base64\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "output_notebook()\n",
    "plotly.offline.init_notebook_mode() # run at the start of every ipython notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据读取与特征选择"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "train_fr_1 = pd.read_csv('./data/fastest_routes_train_part_1.csv')\n",
    "train_fr_2 = pd.read_csv('./data/fastest_routes_train_part_2.csv')\n",
    "train_fr = pd.concat([train_fr_1, train_fr_2])\n",
    "train_fr_new = train_fr[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\n",
    "train_df = pd.read_csv('./data/train.csv')\n",
    "train = pd.merge(train_df, train_fr_new, on = 'id', how = 'left')\n",
    "train_df = train.copy()\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-s)))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# checking if Ids are unique, \n",
    "train_data = train_df.copy()\n",
    "print(\"Number of columns and rows and columns are {} and {} respectively.\".format(train_data.shape[1], train_data.shape[0]))\n",
    "if train_data.id.nunique() == train_data.shape[0]:\n",
    "    print(\"Train ids are unique\")\n",
    "print(\"Number of Nulls - {}.\".format(train_data.isnull().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "旅行持续时间log展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "start = time.time()\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "f, axes = plt.subplots(1, 1, figsize=(11, 7), sharex=True)\n",
    "sns.despine(left=True)\n",
    "sns.distplot(np.log(train_df['trip_duration'].values+1), axlabel = 'Log(trip_duration)', label = 'log(trip_duration)', bins = 50, color=\"r\")\n",
    "plt.setp(axes, yticks=[])\n",
    "plt.tight_layout()\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-start)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "正太分布的，有个别时间有点高的离谱了。。。有个别的神速了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print ('大部分的旅行时间是在：',np.exp(4)/60,np.exp(8)/60)\n",
    "print ('比较吊的。。。',np.exp(2)/60,np.exp(12)/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据提供的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "f, axes = plt.subplots(2,2,figsize=(10, 10), sharex=False, sharey = False)\n",
    "sns.despine(left=True)\n",
    "sns.distplot(train_df['pickup_latitude'].values, label = 'pickup_latitude',color=\"m\",bins = 100, ax=axes[0,0])\n",
    "sns.distplot(train_df['pickup_longitude'].values, label = 'pickup_longitude',color=\"m\",bins =100, ax=axes[0,1])\n",
    "sns.distplot(train_df['dropoff_latitude'].values, label = 'dropoff_latitude',color=\"m\",bins =100, ax=axes[1, 0])\n",
    "sns.distplot(train_df['dropoff_longitude'].values, label = 'dropoff_longitude',color=\"m\",bins =100, ax=axes[1, 1])\n",
    "plt.setp(axes, yticks=[])\n",
    "plt.tight_layout()\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-start)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有些位置是不是太偏僻了，还是统计误差啊，去掉那些离谱的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "纬度控制在40.6到40.9\n",
    "经度控制在-74.05到-73.70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "df = train_df.loc[(train_df.pickup_latitude > 40.6) & (train_df.pickup_latitude < 40.9)]\n",
    "df = df.loc[(df.dropoff_latitude>40.6) & (df.dropoff_latitude < 40.9)]\n",
    "df = df.loc[(df.dropoff_longitude > -74.05) & (df.dropoff_longitude < -73.7)]\n",
    "df = df.loc[(df.pickup_longitude > -74.05) & (df.pickup_longitude < -73.7)]\n",
    "train_data_new = df.copy()\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "f, axes = plt.subplots(2,2,figsize=(12, 12), sharex=False, sharey = False)#\n",
    "sns.despine(left=True)\n",
    "sns.distplot(train_data_new['pickup_latitude'].values, label = 'pickup_latitude',color=\"m\",bins = 100, ax=axes[0,0])\n",
    "sns.distplot(train_data_new['pickup_longitude'].values, label = 'pickup_longitude',color=\"g\",bins =100, ax=axes[0,1])\n",
    "sns.distplot(train_data_new['dropoff_latitude'].values, label = 'dropoff_latitude',color=\"m\",bins =100, ax=axes[1, 0])\n",
    "sns.distplot(train_data_new['dropoff_longitude'].values, label = 'dropoff_longitude',color=\"g\",bins =100, ax=axes[1, 1])\n",
    "plt.setp(axes, yticks=[])\n",
    "plt.tight_layout()\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-start)))\n",
    "print(df.shape[0], train_data.shape[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以黑色为背景"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "temp = train_data.copy()\n",
    "start = time.time()\n",
    "rgb = np.zeros((3000, 3500, 3), dtype=np.uint8)\n",
    "rgb[..., 0] = 0\n",
    "rgb[..., 1] = 0\n",
    "rgb[..., 2] = 0\n",
    "train_data_new['pick_lat_new'] = list(map(int, (train_data_new['pickup_latitude'] - (40.6000))*10000))\n",
    "train_data_new['drop_lat_new'] = list(map(int, (train_data_new['dropoff_latitude'] - (40.6000))*10000))\n",
    "train_data_new['pick_lon_new'] = list(map(int, (train_data_new['pickup_longitude'] - (-74.050))*10000))\n",
    "train_data_new['drop_lon_new'] = list(map(int,(train_data_new['dropoff_longitude'] - (-74.050))*10000))\n",
    "\n",
    "train_data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "summary_plot = pd.DataFrame(train_data_new.groupby(['pick_lat_new', 'pick_lon_new'])['id'].count())\n",
    "\n",
    "summary_plot.reset_index(inplace = True)\n",
    "summary_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lat_list = summary_plot['pick_lat_new'].unique()\n",
    "for i in lat_list:\n",
    "    lon_list = summary_plot.loc[summary_plot['pick_lat_new']==i]['pick_lon_new'].tolist()\n",
    "    unit = summary_plot.loc[summary_plot['pick_lat_new']==i]['id'].tolist()\n",
    "    for j in lon_list:\n",
    "        a = unit[lon_list.index(j)]\n",
    "        if (a//50) >0:\n",
    "            rgb[i][j][0] = 255\n",
    "            rgb[i,j, 1] = 0\n",
    "            rgb[i,j, 2] = 255\n",
    "        elif (a//10)>0:\n",
    "            rgb[i,j, 0] = 0\n",
    "            rgb[i,j, 1] = 255\n",
    "            rgb[i,j, 2] = 0\n",
    "        else:\n",
    "            rgb[i,j, 0] = 255\n",
    "            rgb[i,j, 1] = 0\n",
    "            rgb[i,j, 2] = 0\n",
    "fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(14,20))\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-start)))\n",
    "ax.imshow(rgb, cmap = 'hot')\n",
    "ax.set_axis_off() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 红点表示在给定数据中的1-10次行程具有该点作为起始点\n",
    "- 绿点表示在给定数据中超过10-50次旅行具有该点作为起始点\n",
    "- 黄点表示在给定数据中超过50次以上的行程具有该点作为起始点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征工程：\n",
    "选择对旅途时间有影响的因素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#空间地理距离\n",
    "start = time.time()\n",
    "def haversine_(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"function to calculate haversine distance between two co-ordinates\"\"\"\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lat = lat2 - lat1\n",
    "    lng = lng2 - lng1\n",
    "    d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2\n",
    "    h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d))\n",
    "    return(h)\n",
    "\n",
    "def manhattan_distance_pd(lat1, lng1, lat2, lng2):\n",
    "    \"\"\"function to calculate manhatten distance between pick_drop\"\"\"\n",
    "    a = haversine_(lat1, lng1, lat1, lng2)\n",
    "    b = haversine_(lat1, lng1, lat2, lng1)\n",
    "    return a + b\n",
    "\n",
    "import math\n",
    "def bearing_array(lat1, lng1, lat2, lng2):\n",
    "    AVG_EARTH_RADIUS = 6371  # in km\n",
    "    lng_delta_rad = np.radians(lng2 - lng1)\n",
    "    lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2))\n",
    "    y = np.sin(lng_delta_rad) * np.cos(lat2)\n",
    "    x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad)\n",
    "    return np.degrees(np.arctan2(y, x))\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format((end-start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train_data = temp.copy()\n",
    "train_data['pickup_datetime'] = pd.to_datetime(train_data.pickup_datetime)\n",
    "train_data.loc[:, 'pick_month'] = train_data['pickup_datetime'].dt.month\n",
    "train_data.loc[:, 'hour'] = train_data['pickup_datetime'].dt.hour\n",
    "train_data.loc[:, 'week_of_year'] = train_data['pickup_datetime'].dt.weekofyear\n",
    "train_data.loc[:, 'day_of_year'] = train_data['pickup_datetime'].dt.dayofyear\n",
    "train_data.loc[:, 'day_of_week'] = train_data['pickup_datetime'].dt.dayofweek\n",
    "train_data.loc[:,'hvsine_pick_drop'] = haversine_(train_data['pickup_latitude'].values, train_data['pickup_longitude'].values, train_data['dropoff_latitude'].values, train_data['dropoff_longitude'].values)\n",
    "train_data.loc[:,'manhtn_pick_drop'] = manhattan_distance_pd(train_data['pickup_latitude'].values, train_data['pickup_longitude'].values, train_data['dropoff_latitude'].values, train_data['dropoff_longitude'].values)\n",
    "train_data.loc[:,'bearing'] = bearing_array(train_data['pickup_latitude'].values, train_data['pickup_longitude'].values, train_data['dropoff_latitude'].values, train_data['dropoff_longitude'].values)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "def color(hour):\n",
    "    \"\"\"function for color change in animation\"\"\"\n",
    "    return(10*hour)\n",
    "\n",
    "def Animation(hour, temp, rgb):\n",
    "    \"\"\"Function to generate return a pic of plotings\"\"\"\n",
    "    #ax.clear()\n",
    "    train_data_new = temp.loc[temp['hour'] == hour]\n",
    "    start = time.time()\n",
    "    rgb = np.zeros((3000, 3500, 3), dtype=np.uint8)\n",
    "    rgb[..., 0] = 0\n",
    "    rgb[..., 1] = 0\n",
    "    rgb[..., 2] = 0\n",
    "    train_data_new['pick_lat_new'] = list(map(int, (train_data_new['pickup_latitude'] - (40.6000))*10000))\n",
    "    train_data_new['drop_lat_new'] = list(map(int, (train_data_new['dropoff_latitude'] - (40.6000))*10000))\n",
    "    train_data_new['pick_lon_new'] = list(map(int, (train_data_new['pickup_longitude'] - (-74.050))*10000))\n",
    "    train_data_new['drop_lon_new'] = list(map(int,(train_data_new['dropoff_longitude'] - (-74.050))*10000))\n",
    "\n",
    "    summary_plot = pd.DataFrame(train_data_new.groupby(['pick_lat_new', 'pick_lon_new'])['id'].count())\n",
    "\n",
    "    summary_plot.reset_index(inplace = True)\n",
    "    summary_plot.head(120)\n",
    "    lat_list = summary_plot['pick_lat_new'].unique()\n",
    "    for i in lat_list:\n",
    "        #print(i)\n",
    "        lon_list = summary_plot.loc[summary_plot['pick_lat_new']==i]['pick_lon_new'].tolist()\n",
    "        unit = summary_plot.loc[summary_plot['pick_lat_new']==i]['id'].tolist()\n",
    "        for j in lon_list:\n",
    "            #j = int(j)\n",
    "            a = unit[lon_list.index(j)]\n",
    "            #print(a)\n",
    "            if (a//50) >0:\n",
    "                rgb[i][j][0] = 255 - color(hour)\n",
    "                rgb[i,j, 1] = 255 - color(hour)\n",
    "                rgb[i,j, 2] = 0 + color(hour)\n",
    "            elif (a//10)>0:\n",
    "                rgb[i,j, 0] = 0 + color(hour)\n",
    "                rgb[i,j, 1] = 255 - color(hour)\n",
    "                rgb[i,j, 2] = 0 + color(hour)\n",
    "            else:\n",
    "                rgb[i,j, 0] = 255 - color(hour)\n",
    "                rgb[i,j, 1] = 0 + color(hour)\n",
    "                rgb[i,j, 2] = 0 + color(hour)\n",
    "    #fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(14,20))\n",
    "    end = time.time()\n",
    "    print(\"Time taken by above cell is {} for {}.\".format((end-start), hour))\n",
    "    return(rgb)\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format(end -start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "images_list=[]\n",
    "train_data_new['pickup_datetime'] = pd.to_datetime(train_data_new.pickup_datetime)\n",
    "train_data_new.loc[:, 'hour'] = train_data_new['pickup_datetime'].dt.hour\n",
    "\n",
    "for i in list(range(0, 24)):\n",
    "    im = Animation(i, train_data_new, rgb.copy())\n",
    "    images_list.append(im)\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format(end -start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "def build_gif(imgs = images_list, show_gif=False, save_gif=True, title=''):\n",
    "    \"\"\"function to create a gif of heatmaps\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1,ncols=1,figsize=(10,10))\n",
    "    ax.set_axis_off()\n",
    "    hr_range = list(range(0,24))\n",
    "    def show_im(pairs):\n",
    "        ax.clear()\n",
    "        ax.set_title('Absolute Traffic - Hour ' + str(int(pairs[0])) + ':00')\n",
    "        ax.imshow(pairs[1])\n",
    "        ax.set_axis_off()\n",
    "        return [Artist()]\n",
    "    pairs = list(zip(hr_range, imgs))\n",
    "    #ims = map(lambda x: (ax.imshow(x), ax.set_title(title)), imgs)\n",
    "    im_ani = animation.FuncAnimation(fig, show_im, pairs,interval=500, repeat_delay=0, blit=False)\n",
    "    plt.cla()\n",
    "    if save_gif:\n",
    "        im_ani.save('html/animation.html', writer='imagemagick') #, writer='imagemagick'\n",
    "    if show_gif:\n",
    "        plt.show()\n",
    "    return\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "build_gif()\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特征解释"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "summary_wdays_avg_duration = pd.DataFrame(train_data.groupby(['vendor_id','day_of_week'])['trip_duration'].mean())\n",
    "summary_wdays_avg_duration.reset_index(inplace = True)\n",
    "summary_wdays_avg_duration['unit']=1\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=True)\n",
    "sns.set_context(\"poster\")\n",
    "sns.tsplot(data=summary_wdays_avg_duration, time=\"day_of_week\", unit = \"unit\", condition=\"vendor_id\", value=\"trip_duration\")\n",
    "sns.despine(bottom = False)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "显而易见的是，出租车1类在一周中的所有日子里花费的时间都多于出租车2类，平均差不多多了250秒"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vovin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\", color_codes=True)\n",
    "sns.set_context(\"poster\")\n",
    "train_data2 = train_data.copy()\n",
    "train_data2['trip_duration']= np.log(train_data['trip_duration'])\n",
    "sns.violinplot(x=\"passenger_count\", y=\"trip_duration\", hue=\"vendor_id\", data=train_data2, split=True,\n",
    "               inner=\"quart\",palette={1: \"g\", 2: \"r\"})\n",
    "\n",
    "sns.despine(left=True)\n",
    "print(df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 空载是在刷单吗。。。\n",
    "- 载客人数的分布情况差不多|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box-Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_context(\"poster\")\n",
    "sns.boxplot(x=\"day_of_week\", y=\"trip_duration\", hue=\"vendor_id\", data=train_data, palette=\"PRGn\")\n",
    "plt.ylim(0, 6000)\n",
    "plt.legend(loc = 'upper right')\n",
    "sns.despine(offset=10, trim=True)\n",
    "print(train_data.trip_duration.max())\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 周六日的出行时间更短一些"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line-plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "summary_hour_duration = pd.DataFrame(train_data.groupby(['day_of_week','hour'])['trip_duration'].mean())\n",
    "summary_hour_duration.reset_index(inplace = True)\n",
    "summary_hour_duration['unit']=1\n",
    "sns.set(style=\"white\", palette=\"muted\", color_codes=False)\n",
    "sns.set_context(\"poster\")\n",
    "sns.tsplot(data=summary_hour_duration, time=\"hour\", unit = \"unit\", condition=\"day_of_week\", value=\"trip_duration\")\n",
    "sns.despine(bottom = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 周六日在5点到15点之间还是比较快的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "def assign_cluster(df, k):\n",
    "    \"\"\"function to assign clusters \"\"\"\n",
    "    df_pick = df[['pickup_longitude','pickup_latitude']]\n",
    "    df_drop = df[['dropoff_longitude','dropoff_latitude']]\n",
    "    \"\"\"I am using initialization as from the output of\n",
    "    k-means from my local machine to save time in this kernel\"\"\"\n",
    "    init = np.array([[ -73.98737616,   40.72981533],\n",
    "       [-121.93328857,   37.38933945],\n",
    "       [ -73.78423222,   40.64711269],\n",
    "       [ -73.9546417 ,   40.77377538],\n",
    "       [ -66.84140269,   36.64537175],\n",
    "       [ -73.87040541,   40.77016484],\n",
    "       [ -73.97316185,   40.75814346],\n",
    "       [ -73.98861094,   40.7527791 ],\n",
    "       [ -72.80966949,   51.88108444],\n",
    "       [ -76.99779701,   38.47370625],\n",
    "       [ -73.96975298,   40.69089596],\n",
    "       [ -74.00816622,   40.71414939],\n",
    "       [ -66.97216034,   44.37194443],\n",
    "       [ -61.33552933,   37.85105133],\n",
    "       [ -73.98001393,   40.7783577 ],\n",
    "       [ -72.00626526,   43.20296402],\n",
    "       [ -73.07618713,   35.03469086],\n",
    "       [ -73.95759366,   40.80316361],\n",
    "       [ -79.20167796,   41.04752096],\n",
    "       [ -74.00106031,   40.73867723]])\n",
    "    k_means_pick = KMeans(n_clusters=k, init=init, n_init=1)\n",
    "    k_means_pick.fit(df_pick)\n",
    "    clust_pick = k_means_pick.labels_\n",
    "    df['label_pick'] = clust_pick.tolist()\n",
    "    df['label_drop'] = k_means_pick.predict(df_drop)\n",
    "    return df, k_means_pick\n",
    "\n",
    "end = time.time()\n",
    "print(\"time taken by thie script by now is {}.\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train_cl, k_means = assign_cluster(train_data, 20)  # make it 100 when extracting features \n",
    "centroid_pickups = pd.DataFrame(k_means.cluster_centers_, columns = ['centroid_pick_long', 'centroid_pick_lat'])\n",
    "centroid_dropoff = pd.DataFrame(k_means.cluster_centers_, columns = ['centroid_drop_long', 'centroid_drop_lat'])\n",
    "centroid_pickups['label_pick'] = centroid_pickups.index\n",
    "centroid_dropoff['label_drop'] = centroid_dropoff.index\n",
    "#centroid_pickups.head()\n",
    "train_cl = pd.merge(train_cl, centroid_pickups, how='left', on=['label_pick'])\n",
    "train_cl = pd.merge(train_cl, centroid_dropoff, how='left', on=['label_drop'])\n",
    "#train_cl.head()\n",
    "end = time.time()\n",
    "print(\"Time taken in clustering is {}.\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类相关特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 上下客点所在簇中心点的距离\n",
    "- 方向特征 - 集群质心之间的方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train_cl.loc[:,'hvsine_pick_cent_p'] = haversine_(train_cl['pickup_latitude'].values, train_cl['pickup_longitude'].values, train_cl['centroid_pick_lat'].values, train_cl['centroid_pick_long'].values)\n",
    "train_cl.loc[:,'hvsine_drop_cent_d'] = haversine_(train_cl['dropoff_latitude'].values, train_cl['dropoff_longitude'].values, train_cl['centroid_drop_lat'].values, train_cl['centroid_drop_long'].values)\n",
    "train_cl.loc[:,'hvsine_cent_p_cent_d'] = haversine_(train_cl['centroid_pick_lat'].values, train_cl['centroid_pick_long'].values, train_cl['centroid_drop_lat'].values, train_cl['centroid_drop_long'].values)\n",
    "train_cl.loc[:,'manhtn_pick_cent_p'] = manhattan_distance_pd(train_cl['pickup_latitude'].values, train_cl['pickup_longitude'].values, train_cl['centroid_pick_lat'].values, train_cl['centroid_pick_long'].values)\n",
    "train_cl.loc[:,'manhtn_drop_cent_d'] = manhattan_distance_pd(train_cl['dropoff_latitude'].values, train_cl['dropoff_longitude'].values, train_cl['centroid_drop_lat'].values, train_cl['centroid_drop_long'].values)\n",
    "train_cl.loc[:,'manhtn_cent_p_cent_d'] = manhattan_distance_pd(train_cl['centroid_pick_lat'].values, train_cl['centroid_pick_long'].values, train_cl['centroid_drop_lat'].values, train_cl['centroid_drop_long'].values)\n",
    "\n",
    "train_cl.loc[:,'bearing_pick_cent_p'] = bearing_array(train_cl['pickup_latitude'].values, train_cl['pickup_longitude'].values, train_cl['centroid_pick_lat'].values, train_cl['centroid_pick_long'].values)\n",
    "train_cl.loc[:,'bearing_drop_cent_p'] = bearing_array(train_cl['dropoff_latitude'].values, train_cl['dropoff_longitude'].values, train_cl['centroid_drop_lat'].values, train_cl['centroid_drop_long'].values)\n",
    "train_cl.loc[:,'bearing_cent_p_cent_d'] = bearing_array(train_cl['centroid_pick_lat'].values, train_cl['centroid_pick_long'].values, train_cl['centroid_drop_lat'].values, train_cl['centroid_drop_long'].values)\n",
    "train_cl['speed_hvsn'] = train_cl.hvsine_pick_drop/train_cl.total_travel_time\n",
    "train_cl['speed_manhtn'] = train_cl.manhtn_pick_drop/train_cl.total_travel_time\n",
    "end = time.time()\n",
    "print(\"Time Taken by above cell is {}.\".format(end-start))\n",
    "train_cl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类可视化展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "def cluster_summary(sum_df):\n",
    "    \"\"\"function to calculate summary of given list of clusters \"\"\"\n",
    "    #agg_func = {'trip_duration':'mean','label_drop':'count','bearing':'mean','id':'count'} # that's how you use agg function with groupby\n",
    "    summary_avg_time = pd.DataFrame(sum_df.groupby('label_pick')['trip_duration'].mean())\n",
    "    summary_avg_time.reset_index(inplace = True)\n",
    "    summary_pref_clus = pd.DataFrame(sum_df.groupby(['label_pick', 'label_drop'])['id'].count())\n",
    "    summary_pref_clus = summary_pref_clus.reset_index()\n",
    "    summary_pref_clus = summary_pref_clus.loc[summary_pref_clus.groupby('label_pick')['id'].idxmax()]\n",
    "    summary =pd.merge(summary_avg_time, summary_pref_clus, how = 'left', on = 'label_pick')\n",
    "    summary = summary.rename(columns={'trip_duration':'avg_triptime'})\n",
    "    return summary\n",
    "end = time.time()\n",
    "print(\"Time Taken by above cell is {}.\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "def show_fmaps(train_data, path=1):\n",
    "    \"\"\"function to generate map and add the pick up and drop coordinates\n",
    "    1. Path = 1 : Join pickup (blue) and drop(red) using a straight line\n",
    "    \"\"\"\n",
    "    full_data = train_data\n",
    "    summary_full_data = pd.DataFrame(full_data.groupby('label_pick')['id'].count())\n",
    "    summary_full_data.reset_index(inplace = True)\n",
    "    summary_full_data = summary_full_data.loc[summary_full_data['id']>70000]\n",
    "    map_1 = folium.Map(location=[40.767937, -73.982155], zoom_start=10,tiles='Stamen Toner') # manually added centre\n",
    "    new_df = train_data.loc[train_data['label_pick'].isin(summary_full_data.label_pick.tolist())].sample(50)\n",
    "    new_df.reset_index(inplace = True, drop = True)\n",
    "    for i in range(new_df.shape[0]):\n",
    "        pick_long = new_df.loc[new_df.index ==i]['pickup_longitude'].values[0]\n",
    "        pick_lat = new_df.loc[new_df.index ==i]['pickup_latitude'].values[0]\n",
    "        dest_long = new_df.loc[new_df.index ==i]['dropoff_longitude'].values[0]\n",
    "        dest_lat = new_df.loc[new_df.index ==i]['dropoff_latitude'].values[0]\n",
    "        folium.Marker([pick_lat, pick_long]).add_to(map_1)\n",
    "        folium.Marker([dest_lat, dest_long]).add_to(map_1)\n",
    "    return map_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "重点的clusters：大于70000个记录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def clusters_map(clus_data, full_data, tile = 'OpenStreetMap', sig = 0, zoom = 12, circle = 0, radius_ = 30):\n",
    "    \"\"\" function to plot clusters on map\"\"\"\n",
    "    map_1 = folium.Map(location=[40.767937, -73.982155], zoom_start=zoom,tiles= tile) # 'Mapbox' 'Stamen Toner'\n",
    "    summary_full_data = pd.DataFrame(full_data.groupby('label_pick')['id'].count())\n",
    "    summary_full_data.reset_index(inplace = True)\n",
    "    if sig == 1:\n",
    "        summary_full_data = summary_full_data.loc[summary_full_data['id']>70000]\n",
    "    sig_cluster = summary_full_data['label_pick'].tolist()\n",
    "    clus_summary = cluster_summary(full_data)\n",
    "    for i in sig_cluster:\n",
    "        pick_long = clus_data.loc[clus_data.index ==i]['centroid_pick_long'].values[0]\n",
    "        pick_lat = clus_data.loc[clus_data.index ==i]['centroid_pick_lat'].values[0]\n",
    "        clus_no = clus_data.loc[clus_data.index ==i]['label_pick'].values[0]\n",
    "        most_visited_clus = clus_summary.loc[clus_summary['label_pick']==i]['label_drop'].values[0]\n",
    "        avg_triptime = clus_summary.loc[clus_summary['label_pick']==i]['avg_triptime'].values[0]\n",
    "        pop = 'cluster = '+str(clus_no)+' & most visited cluster = ' +str(most_visited_clus) +' & avg triptime from this cluster =' + str(avg_triptime)\n",
    "        if circle == 1:\n",
    "            folium.CircleMarker(location=[pick_lat, pick_long], radius=radius_,\n",
    "                    color='#F08080',\n",
    "                    fill_color='#3186cc', popup=pop).add_to(map_1)\n",
    "        folium.Marker([pick_lat, pick_long], popup=pop).add_to(map_1)\n",
    "    return map_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "osm = show_fmaps(train_data, path=1)\n",
    "osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clus_map = clusters_map(centroid_pickups, train_cl, sig =0, zoom =3.2, circle =1, tile = 'Stamen Terrain')\n",
    "clus_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "clus_map_sig = clusters_map(centroid_pickups, train_cl, sig =1, circle =1)\n",
    "clus_map_sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集进行相同的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('./data/test.csv')\n",
    "test_fr = pd.read_csv('./data/fastest_routes_test.csv')\n",
    "test_fr_new = test_fr[['id', 'total_distance', 'total_travel_time', 'number_of_steps']]\n",
    "test_df = pd.merge(test_df, test_fr_new, on = 'id', how = 'left')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "时间特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_data = test_df.copy()\n",
    "test_data['pickup_datetime'] = pd.to_datetime(test_data.pickup_datetime)\n",
    "test_data.loc[:, 'pick_month'] = test_data['pickup_datetime'].dt.month\n",
    "test_data.loc[:, 'hour'] = test_data['pickup_datetime'].dt.hour\n",
    "test_data.loc[:, 'week_of_year'] = test_data['pickup_datetime'].dt.weekofyear\n",
    "test_data.loc[:, 'day_of_year'] = test_data['pickup_datetime'].dt.dayofyear\n",
    "test_data.loc[:, 'day_of_week'] = test_data['pickup_datetime'].dt.dayofweek\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "距离特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "strat = time.time()\n",
    "test_data.loc[:,'hvsine_pick_drop'] = haversine_(test_data['pickup_latitude'].values, test_data['pickup_longitude'].values, test_data['dropoff_latitude'].values, test_data['dropoff_longitude'].values)\n",
    "test_data.loc[:,'manhtn_pick_drop'] = manhattan_distance_pd(test_data['pickup_latitude'].values, test_data['pickup_longitude'].values, test_data['dropoff_latitude'].values, test_data['dropoff_longitude'].values)\n",
    "test_data.loc[:,'bearing'] = bearing_array(test_data['pickup_latitude'].values, test_data['pickup_longitude'].values, test_data['dropoff_latitude'].values, test_data['dropoff_longitude'].values)\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format(end-strat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聚类特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_data['label_pick'] = k_means.predict(test_data[['pickup_longitude','pickup_latitude']])\n",
    "test_data['label_drop'] = k_means.predict(test_data[['dropoff_longitude','dropoff_latitude']])\n",
    "test_cl = pd.merge(test_data, centroid_pickups, how='left', on=['label_pick'])\n",
    "test_cl = pd.merge(test_cl, centroid_dropoff, how='left', on=['label_drop'])\n",
    "#test_cl.head()\n",
    "end = time.time()\n",
    "print(\"Time Taken by above cell is {}.\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_cl.loc[:,'hvsine_pick_cent_p'] = haversine_(test_cl['pickup_latitude'].values, test_cl['pickup_longitude'].values, test_cl['centroid_pick_lat'].values, test_cl['centroid_pick_long'].values)\n",
    "test_cl.loc[:,'hvsine_drop_cent_d'] = haversine_(test_cl['dropoff_latitude'].values, test_cl['dropoff_longitude'].values, test_cl['centroid_drop_lat'].values, test_cl['centroid_drop_long'].values)\n",
    "test_cl.loc[:,'hvsine_cent_p_cent_d'] = haversine_(test_cl['centroid_pick_lat'].values, test_cl['centroid_pick_long'].values, test_cl['centroid_drop_lat'].values, test_cl['centroid_drop_long'].values)\n",
    "test_cl.loc[:,'manhtn_pick_cent_p'] = manhattan_distance_pd(test_cl['pickup_latitude'].values, test_cl['pickup_longitude'].values, test_cl['centroid_pick_lat'].values, test_cl['centroid_pick_long'].values)\n",
    "test_cl.loc[:,'manhtn_drop_cent_d'] = manhattan_distance_pd(test_cl['dropoff_latitude'].values, test_cl['dropoff_longitude'].values, test_cl['centroid_drop_lat'].values, test_cl['centroid_drop_long'].values)\n",
    "test_cl.loc[:,'manhtn_cent_p_cent_d'] = manhattan_distance_pd(test_cl['centroid_pick_lat'].values, test_cl['centroid_pick_long'].values, test_cl['centroid_drop_lat'].values, test_cl['centroid_drop_long'].values)\n",
    "\n",
    "test_cl.loc[:,'bearing_pick_cent_p'] = bearing_array(test_cl['pickup_latitude'].values, test_cl['pickup_longitude'].values, test_cl['centroid_pick_lat'].values, test_cl['centroid_pick_long'].values)\n",
    "test_cl.loc[:,'bearing_drop_cent_p'] = bearing_array(test_cl['dropoff_latitude'].values, test_cl['dropoff_longitude'].values, test_cl['centroid_drop_lat'].values, test_cl['centroid_drop_long'].values)\n",
    "test_cl.loc[:,'bearing_cent_p_cent_d'] = bearing_array(test_cl['centroid_pick_lat'].values, test_cl['centroid_pick_long'].values, test_cl['centroid_drop_lat'].values, test_cl['centroid_drop_long'].values)\n",
    "test_cl['speed_hvsn'] = test_cl.hvsine_pick_drop/test_cl.total_travel_time\n",
    "test_cl['speed_manhtn'] = test_cl.manhtn_pick_drop/test_cl.total_travel_time\n",
    "end = time.time()\n",
    "print(\"Time Taken by above cell is {}.\".format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_cl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以尝试加入PCA特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Lets Add PCA features in the model, reference Beluga's PCA\n",
    "train = train_cl\n",
    "test = test_cl\n",
    "start = time.time()\n",
    "coords = np.vstack((train[['pickup_latitude', 'pickup_longitude']].values,\n",
    "                    train[['dropoff_latitude', 'dropoff_longitude']].values,\n",
    "                    test[['pickup_latitude', 'pickup_longitude']].values,\n",
    "                    test[['dropoff_latitude', 'dropoff_longitude']].values))\n",
    "\n",
    "pca = PCA().fit(coords)\n",
    "train['pickup_pca0'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "train['pickup_pca1'] = pca.transform(train[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "train['dropoff_pca0'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "train['dropoff_pca1'] = pca.transform(train[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "test['pickup_pca0'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 0]\n",
    "test['pickup_pca1'] = pca.transform(test[['pickup_latitude', 'pickup_longitude']])[:, 1]\n",
    "test['dropoff_pca0'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 0]\n",
    "test['dropoff_pca1'] = pca.transform(test[['dropoff_latitude', 'dropoff_longitude']])[:, 1]\n",
    "end = time.time()\n",
    "print(\"Time Taken by above cell is {}.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train['store_and_fwd_flag_int'] = np.where(train['store_and_fwd_flag']=='N', 0, 1)\n",
    "test['store_and_fwd_flag_int'] = np.where(test['store_and_fwd_flag']=='N', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "feature_names = list(train.columns)\n",
    "print(\"Difference of features in train and test are {}\".format(np.setdiff1d(train.columns, test.columns)))\n",
    "print(\"\")\n",
    "do_not_use_for_training = ['pick_date','id', 'pickup_datetime', 'dropoff_datetime', 'trip_duration', 'store_and_fwd_flag']\n",
    "feature_names = [f for f in train.columns if f not in do_not_use_for_training]\n",
    "print(\"We will be using following features for training {}.\".format(feature_names))\n",
    "print(\"\")\n",
    "print(\"Total number of features are {}.\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y = np.log(train['trip_duration'].values + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "dtest = xgb.DMatrix(test[feature_names].values)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 10,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "\n",
    "# You could try to train with more epoch\n",
    "model = xgb.train(xgb_pars, dtrain, 15, watchlist, early_stopping_rounds=2,\n",
    "                  maximize=False, verbose_eval=1)\n",
    "end = time.time()\n",
    "print(\"Time taken by above cell is {}.\".format(end - start))\n",
    "print('Modeling RMSLE %.5f' % model.best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入更多特征"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "天气特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "weather = pd.read_csv('./data/weather_data_nyc_centralpark_2016.csv')\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from ggplot import *\n",
    "weather.date = pd.to_datetime(weather.date)\n",
    "weather['day_of_year']= weather.date.dt.dayofyear\n",
    "p = ggplot(aes(x='date'),data=weather) + geom_line(aes(y='minimum temperature', colour = \"blue\")) + geom_line(aes(y='maximum temperature', colour = \"red\"))\n",
    "p + geom_point(aes(y='minimum temperature',colour = \"blue\")) #+ stat_smooth(colour='yellow', span=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下雪，降雨，积雪情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "weather['precipitation'].unique()\n",
    "weather['precipitation'] = np.where(weather['precipitation']=='T', '0.00',weather['precipitation'])\n",
    "weather['precipitation'] = list(map(float, weather['precipitation']))\n",
    "weather['snow fall'] = np.where(weather['snow fall']=='T', '0.00',weather['snow fall'])\n",
    "weather['snow fall'] = list(map(float, weather['snow fall']))\n",
    "weather['snow depth'] = np.where(weather['snow depth']=='T', '0.00',weather['snow depth'])\n",
    "weather['snow depth'] = list(map(float, weather['snow depth']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "random_x = weather['date'].values\n",
    "random_y0 = weather['precipitation']\n",
    "random_y1 = weather['snow fall']\n",
    "random_y2 = weather['snow depth']\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import plotly\n",
    "random_x = weather['date'].values\n",
    "random_y0 = weather['precipitation']\n",
    "random_y1 = weather['snow fall']\n",
    "random_y2 = weather['snow depth']\n",
    "\n",
    "# Create traces\n",
    "trace0 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y0,\n",
    "    mode = 'markers',\n",
    "    name = 'precipitation'\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y1,\n",
    "    mode = 'markers',\n",
    "    name = 'snow fall'\n",
    ")\n",
    "trace2 = go.Scatter(\n",
    "    x = random_x,\n",
    "    y = random_y2,\n",
    "    mode = 'markers',\n",
    "    name = 'snow depth'\n",
    ")\n",
    "\n",
    "data = [trace0, trace1, trace2]\n",
    "plotly.offline.iplot(data, filename='scatter-mode')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "动作方向"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def freq_turn(step_dir):\n",
    "    \"\"\"function to create dummy for turn type\"\"\"\n",
    "    from collections import Counter\n",
    "    step_dir_new = step_dir.split(\"|\")\n",
    "    a_list = Counter(step_dir_new).most_common()\n",
    "    path = {}\n",
    "    for i in range(len(a_list)):\n",
    "        path.update({a_list[i]})\n",
    "    a = 0\n",
    "    b = 0\n",
    "    c = 0\n",
    "    if 'straight' in (path.keys()):\n",
    "        a = path['straight']\n",
    "        #print(a)\n",
    "    if 'left' in (path.keys()):\n",
    "        b = path['left']\n",
    "        #print(b)\n",
    "    if 'right' in (path.keys()):\n",
    "        c = path['right']\n",
    "        #print(c)\n",
    "    return a,b,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "train_fr['straight']= 0\n",
    "train_fr['left'] =0\n",
    "train_fr['right'] = 0\n",
    "train_fr['straight'], train_fr['left'], train_fr['right'] = zip(*train_fr['step_direction'].map(freq_turn))\n",
    "end = time.time()\n",
    "print(\"Time Taken by above cell is {}.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train_fr_new = train_fr[['id','straight','left','right']]\n",
    "train = pd.merge(train, train_fr_new, on = 'id', how = 'left')\n",
    "#train = pd.merge(train, weather, on= 'date', how = 'left')\n",
    "print(len(train.columns))\n",
    "#train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加入天气特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])\n",
    "train['date'] = train['pickup_datetime'].dt.date\n",
    "train.head()\n",
    "\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "train = pd.merge(train, weather[['date','minimum temperature', 'precipitation', 'snow fall', 'snow depth']], on= 'date', how = 'left')\n",
    "train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "train.loc[:,'hvsine_pick_cent_d'] = haversine_(train['pickup_latitude'].values, train['pickup_longitude'].values, train['centroid_drop_lat'].values, train['centroid_drop_long'].values)\n",
    "train.loc[:,'hvsine_drop_cent_p'] = haversine_(train['dropoff_latitude'].values, train['dropoff_longitude'].values, train['centroid_pick_lat'].values, train['centroid_pick_long'].values)\n",
    "\n",
    "test.loc[:,'hvsine_pick_cent_d'] = haversine_(test['pickup_latitude'].values, test['pickup_longitude'].values, test['centroid_drop_lat'].values, test['centroid_drop_long'].values)\n",
    "test.loc[:,'hvsine_drop_cent_p'] = haversine_(test['dropoff_latitude'].values, test['dropoff_longitude'].values, test['centroid_pick_lat'].values, test['centroid_pick_long'].values)\n",
    "\n",
    "print(\"shape of train_features is {}.\".format(len(train.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试集才用相同的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "test_fr['straight']= 0\n",
    "test_fr['left'] =0\n",
    "test_fr['right'] = 0\n",
    "test_fr['straight'], test_fr['left'], test_fr['right'] = zip(*test_fr['step_direction'].map(freq_turn))\n",
    "end = time.time()\n",
    "print(\"Time Taken by above cell is {}.\".format(end - start))\n",
    "#test_fr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test_fr_new = test_fr[['id','straight','left','right']]\n",
    "test = pd.merge(test, test_fr_new, on = 'id', how = 'left')\n",
    "print(len(test.columns))\n",
    "#test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])\n",
    "test['date'] = test['pickup_datetime'].dt.date\n",
    "test['date'] = pd.to_datetime(test['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "test= pd.merge(test, weather[['date','minimum temperature', 'precipitation', 'snow fall', 'snow depth']], on= 'date', how = 'left')\n",
    "feature_names = list(train.columns)\n",
    "print(\"Difference of features in train and test are {}\".format(np.setdiff1d(train.columns, test.columns)))\n",
    "print(\"\")\n",
    "do_not_use_for_training = ['pick_date','id', 'pickup_datetime', 'dropoff_datetime', 'trip_duration', 'store_and_fwd_flag', 'date']\n",
    "feature_names = [f for f in train.columns if f not in do_not_use_for_training]\n",
    "print(\"We will be using following features for training {}.\".format(feature_names))\n",
    "print(\"\")\n",
    "print(\"Total number of features are {}.\".format(len(feature_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "y = np.log(train['trip_duration'].values + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "Xtr, Xv, ytr, yv = train_test_split(train[feature_names].values, y, test_size=0.2, random_state=1987)\n",
    "dtrain = xgb.DMatrix(Xtr, label=ytr)\n",
    "dvalid = xgb.DMatrix(Xv, label=yv)\n",
    "dtest = xgb.DMatrix(test[feature_names].values)\n",
    "watchlist = [(dtrain, 'train'), (dvalid, 'valid')]\n",
    "\n",
    "start = time.time()\n",
    "xgb_pars = {'min_child_weight': 50, 'eta': 0.3, 'colsample_bytree': 0.3, 'max_depth': 10,\n",
    "            'subsample': 0.8, 'lambda': 1., 'nthread': -1, 'booster' : 'gbtree', 'silent': 1,\n",
    "            'eval_metric': 'rmse', 'objective': 'reg:linear'}\n",
    "\n",
    "model_1 = xgb.train(xgb_par, dtrain, 100, watchlist, early_stopping_rounds=4, maximize=False, verbose_eval=1)\n",
    "print('Modeling RMSLE %.5f' % model.best_score)\n",
    "end = time.time()\n",
    "print(\"Time taken in training is {}.\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print('Modeling RMSLE %.5f' % model_1.best_score)\n",
    "end = time.time()\n",
    "print(\"Time taken in training is {}.\".format(end - start))\n",
    "start = time.time()\n",
    "yvalid = model_1.predict(dvalid)\n",
    "ytest = model_1.predict(dtest)\n",
    "end = time.time()\n",
    "print(\"Time taken in prediction is {}.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "if test.shape[0] == ytest.shape[0]:\n",
    "    print('Test shape OK.') \n",
    "test['trip_duration'] = np.exp(ytest) - 1\n",
    "test[['id', 'trip_duration']].to_csv('mahesh_xgb_submission.csv', index=False)\n",
    "end = time.time()\n",
    "print(\"Time taken in training is {}.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}